# ============================================
# AI Guardian Lab - Universal Configuration
# ============================================
# Copy this file to .env and configure your settings
# cp .env.example .env

# ============================================
# QUICK START RECOMMENDATIONS
# ============================================
# üè† LOCAL (Privacy + Free): Ollama (install: https://ollama.ai)
# ‚òÅÔ∏è  CLOUD FREE TIER: Groq (fast, limited quota: https://console.groq.com)
# üí∞ CLOUD PAID: OpenAI GPT-4 (best quality), Anthropic Claude, DeepSeek (cheapest)
# 
# MULTI-PROVIDER FALLBACK: Set primary provider below, add API keys for backups.
# LiteLLM automatically falls back if primary fails.

# ============================================
# LLM PROVIDER CONFIGURATION
# ============================================
# Supported: ollama, openai, anthropic, deepseek, gemini, groq, azure, cohere
# Full list: https://docs.litellm.ai/docs/providers

LLM_PROVIDER=ollama

# --------------------------------------------
# Ollama (Local - DEFAULT - Privacy First)
# --------------------------------------------
# RECOMMENDED FOR: Development, privacy-sensitive tasks, offline work
# Install: https://ollama.ai/download
# Remote Ollama: Change localhost to your server IP (e.g., 192.168.1.100:11434)

OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL_CODER=qwen2.5-coder:7b
OLLAMA_MODEL_EXPLAIN=llama3.2:3b-instruct-q4_K_M

# Models you can pull: ollama pull qwen2.5-coder:7b
# Alternative models:
#   - codellama:7b (Meta, code-focused)
#   - deepseek-coder:6.7b (code generation)
#   - llama3.2:3b (general, lightweight)

# --------------------------------------------
# Groq (Cloud - FREE TIER - Fast Inference)
# --------------------------------------------
# RECOMMENDED FOR: Users without local GPU, quick testing, free tier
# Get API key: https://console.groq.com (free signup, rate limits apply)
# FALLBACK: Uncomment to use if Ollama unavailable

# LLM_PROVIDER=groq
# GROQ_API_KEY=gsk_xxxxxxxxxxxxx
# LLM_MODEL_CODER=llama-3.3-70b-versatile
# LLM_MODEL_EXPLAIN=llama-3.1-8b-instant

# --------------------------------------------
# OpenAI (Cloud - Production Grade)
# --------------------------------------------
# RECOMMENDED FOR: Production, best quality, complex tasks
# Get API key: https://platform.openai.com/api-keys
# COST: ~$0.01-0.03 per command generation

# LLM_PROVIDER=openai
# OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxx
# LLM_MODEL_CODER=gpt-4o
# LLM_MODEL_EXPLAIN=gpt-4o-mini

# --------------------------------------------
# Anthropic Claude (Cloud - Safe + Smart)
# --------------------------------------------
# RECOMMENDED FOR: Complex reasoning, long context, safety-critical tasks
# Get API key: https://console.anthropic.com
# COST: ~$0.015 per command generation

# LLM_PROVIDER=anthropic
# ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxx
# LLM_MODEL_CODER=claude-3-5-sonnet-20241022
# LLM_MODEL_EXPLAIN=claude-3-5-haiku-20241022

# --------------------------------------------
# DeepSeek (Cloud - Most Cost Effective)
# --------------------------------------------
# RECOMMENDED FOR: Budget-conscious users, high volume
# Get API key: https://platform.deepseek.com
# COST: ~$0.001 per command generation (100x cheaper than OpenAI)

# LLM_PROVIDER=deepseek
# DEEPSEEK_API_KEY=sk-xxxxxxxxxxxxx
# LLM_MODEL_CODER=deepseek-coder
# LLM_MODEL_EXPLAIN=deepseek-chat

# --------------------------------------------
# Google Gemini (Cloud)
# --------------------------------------------
# Get API key: https://makersuite.google.com/app/apikey

# LLM_PROVIDER=gemini
# GEMINI_API_KEY=xxxxxxxxxxxxx
# LLM_MODEL_CODER=gemini-1.5-pro
# LLM_MODEL_EXPLAIN=gemini-1.5-flash

# --------------------------------------------
# LM Studio (Local - OpenAI Compatible)
# --------------------------------------------
# Install: https://lmstudio.ai (GUI for local models)

# LLM_PROVIDER=openai
# OPENAI_API_BASE=http://localhost:1234/v1
# OPENAI_API_KEY=lm-studio
# LLM_MODEL_CODER=local-model
# LLM_MODEL_EXPLAIN=local-model

# --------------------------------------------
# Azure OpenAI (Enterprise)
# --------------------------------------------
# LLM_PROVIDER=azure
# AZURE_API_KEY=xxxxxxxxxxxxx
# AZURE_API_BASE=https://your-resource.openai.azure.com
# AZURE_API_VERSION=2024-02-15-preview
# LLM_MODEL_CODER=gpt-4
# LLM_MODEL_EXPLAIN=gpt-35-turbo

# ============================================
# MULTI-PROVIDER FALLBACK (Advanced)
# ============================================
# LiteLLM supports automatic fallback. Add multiple API keys:
# 1. Set primary provider above
# 2. Uncomment backup provider keys
# 3. LiteLLM tries fallbacks automatically on failure
#
# Example setup:
#   LLM_PROVIDER=ollama (primary)
#   GROQ_API_KEY=gsk_xxx (fallback if Ollama down)
#   OPENAI_API_KEY=sk-xxx (final fallback)

# ============================================
# GUARDIAN CONFIGURATION
# ============================================
GUARDIAN_URL=http://guardian:5000
GUARDIAN_PATTERNS_FILE=/app/config/patterns.yaml

# ============================================
# NETWORK & PORTS
# ============================================
GUARDIAN_PORT=5000
AGENT_PORT=5001
UI_PORT=8080

# Docker network (auto-assigned if omitted)
# Change only if conflicts with existing Docker networks
# DOCKER_NETWORK_SUBNET=172.30.0.0/24

# ============================================
# DATABASE
# ============================================
DB_PATH=/app/database/audit.db

# ============================================
# WORKSPACE & SECURITY
# ============================================
WORKSPACE_DIR=./workspace
EXEC_UID=1000
EXEC_GID=1000
SANDBOX_MODE=false

# ============================================
# LOGGING
# ============================================
LOG_LEVEL=INFO
LOG_FORMAT=text

# ============================================
# PATTERN LEARNING
# ============================================
PATTERN_CONFIDENCE_THRESHOLD=30
PATTERN_LEARNING_SAMPLE_SIZE=100

